{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SAM_titanic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2XdIDbdlejUk"
      },
      "source": [
        "## プログラム実行前の設定など"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWgy0z6d2LB2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "ae5cdb10-151b-402e-830d-46eecefa6e02"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jul 12 12:37:47 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CQNWxDJAfAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b43ed94c-1860-431a-fced-462e0c9653d9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_m-a1kUAjFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"./drive/My Drive/causal_book/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QZagoIYv44f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "a340ebc3-be56-4ca6-c265-1b8a36768592"
      },
      "source": [
        "# PyTorchのバージョンを下げる\n",
        "!pip install torch==1.4.0+cu92 torchvision==0.5.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.4.0+cu92\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torch-1.4.0%2Bcu92-cp36-cp36m-linux_x86_64.whl (640.5MB)\n",
            "\u001b[K     |████████████████████████████████| 640.6MB 27kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5.0+cu92\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.5.0%2Bcu92-cp36-cp36m-linux_x86_64.whl (3.9MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 68.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0+cu92) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0+cu92) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0+cu92) (1.12.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "  Found existing installation: torchvision 0.6.1+cu101\n",
            "    Uninstalling torchvision-0.6.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.1+cu101\n",
            "Successfully installed torch-1.4.0+cu92 torchvision-0.5.0+cu92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqh9FyP-wHGa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8bfcf89a-e43a-4ecb-eae8-4dd73bbbe0b5"
      },
      "source": [
        "import torch \n",
        "print(torch.__version__)  # 元は1.5.0+cu101、versionを1.4に下げた"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.0+cu92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XZFKJwcu-_Oj",
        "colab": {}
      },
      "source": [
        "# 乱数のシードを設定\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hx1idArc_F15",
        "colab": {}
      },
      "source": [
        "# 使用するパッケージ（ライブラリと関数）を定義\n",
        "# 標準正規分布の生成用\n",
        "from numpy.random import *\n",
        "\n",
        "# グラフの描画用\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# その他\n",
        "import pandas as pd\n",
        "\n",
        "# シグモイド関数をimport\n",
        "from scipy.special import expit\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AWqP6yeQlI_t"
      },
      "source": [
        "## データの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXD1DQWsARyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#タイタニックデータ読み込み\n",
        "df = pd.read_csv('titanic.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i30rVoXnBho_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#不要な列・欠損が多い列を削除し、カテゴリを数値に変換\n",
        "df = df.drop('PassengerId',axis=1).drop('Name',axis=1).drop('Ticket',axis=1).drop('Cabin',axis=1)\n",
        "df = pd.get_dummies(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQg4ew9SA3Fg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6ad5b8a7-cf52-4dd4-a26c-d5807c76eb95"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Sex_female</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Pclass   Age  SibSp  ...  Sex_male  Embarked_C  Embarked_Q  Embarked_S\n",
              "0         0       3  22.0      1  ...         1           0           0           1\n",
              "1         1       1  38.0      1  ...         0           1           0           0\n",
              "2         1       3  26.0      0  ...         0           0           0           1\n",
              "3         1       1  35.0      1  ...         0           0           0           1\n",
              "4         0       3  35.0      0  ...         1           0           0           1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K4_yiooBKI6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be5c514f-7e7b-4d43-ac6c-0ff1ff63e63a"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoGqhUmBH29j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "3e152c0f-3d07-47e4-ba34-03e9bc7f4b17"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Survived        0\n",
              "Pclass          0\n",
              "Age           177\n",
              "SibSp           0\n",
              "Parch           0\n",
              "Fare            0\n",
              "Sex_female      0\n",
              "Sex_male        0\n",
              "Embarked_C      0\n",
              "Embarked_Q      0\n",
              "Embarked_S      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhv1vAvzH-Xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Age'] = df['Age'].fillna(df['Age'].mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaITeOHmIBU-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8c3554fe-0099-4f64-cc07-7ebf2c91b360"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Survived      0\n",
              "Pclass        0\n",
              "Age           0\n",
              "SibSp         0\n",
              "Parch         0\n",
              "Fare          0\n",
              "Sex_female    0\n",
              "Sex_male      0\n",
              "Embarked_C    0\n",
              "Embarked_Q    0\n",
              "Embarked_S    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1TPIeXDg6QDG"
      },
      "source": [
        "## SAMによる推論を実施"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "edNNPSLY6u6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "338426a4-3a03-478e-ff31-c98597f010f8"
      },
      "source": [
        "!pip install cdt==0.5.18"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cdt==0.5.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/29/144be44af187c8a2af63ceb205c38ca11787589f532cdf76517333d92d90/cdt-0.5.18-py3-none-any.whl (917kB)\n",
            "\r\u001b[K     |▍                               | 10kB 23.9MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 4.3MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40kB 4.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 61kB 4.2MB/s eta 0:00:01\r\u001b[K     |██▌                             | 71kB 4.6MB/s eta 0:00:01\r\u001b[K     |██▉                             | 81kB 5.0MB/s eta 0:00:01\r\u001b[K     |███▏                            | 92kB 5.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 102kB 5.1MB/s eta 0:00:01\r\u001b[K     |████                            | 112kB 5.1MB/s eta 0:00:01\r\u001b[K     |████▎                           | 122kB 5.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 133kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 143kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 153kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 163kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 174kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 184kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 194kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 204kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 215kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 225kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 235kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 245kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 256kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 266kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 276kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 286kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 296kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 307kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 317kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 327kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 337kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 348kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 358kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 368kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 378kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 389kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 399kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 409kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 419kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 430kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 440kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 450kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 460kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 471kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 481kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 491kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 501kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 512kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 522kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 532kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 542kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 552kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 563kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 573kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 583kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 593kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 604kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 614kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 624kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 634kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 645kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 655kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 665kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 675kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 686kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 696kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 706kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 716kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 727kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 737kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 747kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 757kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 768kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 778kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 788kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 798kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 808kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 819kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 829kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 839kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 849kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 860kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 870kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 880kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 890kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 901kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 911kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 921kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from cdt==0.5.18) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from cdt==0.5.18) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cdt==0.5.18) (1.18.5)\n",
            "Collecting skrebate\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/01/764fdd40b0e9f01624725c3cf1ffa00071fabb66b62d39fc2c28b34f3edb/skrebate-0.6.tar.gz\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cdt==0.5.18) (0.15.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from cdt==0.5.18) (0.10.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cdt==0.5.18) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from cdt==0.5.18) (2.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from cdt==0.5.18) (1.0.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from cdt==0.5.18) (0.22.2.post1)\n",
            "Collecting GPUtil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->cdt==0.5.18) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->cdt==0.5.18) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->cdt==0.5.18) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->cdt==0.5.18) (3.0.4)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->cdt==0.5.18) (0.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->cdt==0.5.18) (4.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->cdt==0.5.18) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->cdt==0.5.18) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.0->statsmodels->cdt==0.5.18) (1.12.0)\n",
            "Building wheels for collected packages: skrebate, GPUtil\n",
            "  Building wheel for skrebate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for skrebate: filename=skrebate-0.6-cp36-none-any.whl size=29329 sha256=26db39f2a7a3f8c368807bc7cbd23b22e220ae5553775615bd6201c5bef57cdb\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/99/36/c827bcfa6852c6d068895b2723c57cea84f93642270c6dc05c\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=d6799d95e261ba7c97fb75e9d6c1e892b1068e1556ebac4e935371b87060618b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built skrebate GPUtil\n",
            "Installing collected packages: skrebate, GPUtil, cdt\n",
            "Successfully installed GPUtil-1.4.0 cdt-0.5.18 skrebate-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ihTvgRcv1E8s"
      },
      "source": [
        "### SAMの識別器Dの実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sJQ2_9LY8MQ8",
        "colab": {}
      },
      "source": [
        "# PyTorchから使用するものをimport\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class SAMDiscriminator(nn.Module):\n",
        "    \"\"\"SAMのDiscriminatorのニューラルネットワーク\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, nfeatures, dnh, hlayers):\n",
        "        super(SAMDiscriminator, self).__init__()\n",
        "\n",
        "        # ----------------------------------\n",
        "        # ネットワークの用意\n",
        "        # ----------------------------------\n",
        "        self.nfeatures = nfeatures  # 入力変数の数\n",
        "\n",
        "        layers = []\n",
        "        layers.append(nn.Linear(nfeatures, dnh))\n",
        "        layers.append(nn.BatchNorm1d(dnh))\n",
        "        layers.append(nn.LeakyReLU(.2))\n",
        "\n",
        "        for i in range(hlayers-1):\n",
        "            layers.append(nn.Linear(dnh, dnh))\n",
        "            layers.append(nn.BatchNorm1d(dnh))\n",
        "            layers.append(nn.LeakyReLU(.2))\n",
        "\n",
        "        layers.append(nn.Linear(dnh, 1))  # 最終出力\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "        # ----------------------------------\n",
        "        # maskの用意（対角成分のみ1で、他は0の行列）\n",
        "        # ----------------------------------\n",
        "        mask = torch.eye(nfeatures, nfeatures)  # 変数の数×変数の数の単位行列\n",
        "        self.register_buffer(\"mask\", mask.unsqueeze(0))  # 単位行列maskを保存しておく\n",
        "\n",
        "        # 注意：register_bufferはmodelのパラメータではないが、その後forwardで使う変数を登録するPyTorchのメソッドです\n",
        "        # self.変数名で、以降も使用可能になります\n",
        "        # https://pytorch.org/docs/stable/nn.html?highlight=register_buffer#torch.nn.Module.register_buffer\n",
        "\n",
        "    def forward(self, input, obs_data=None):\n",
        "        \"\"\"　順伝搬の計算\n",
        "        Args:\n",
        "            input (torch.Size([データ数, 観測変数の種類数])): 観測したデータ、もしくは生成されたデータ\n",
        "            obs_data (torch.Size([データ数, 観測変数の種類数])):観測したデータ\n",
        "        Returns:\n",
        "            torch.Tensor: 観測したデータか、それとも生成されたデータかの判定結果\n",
        "        \"\"\"\n",
        "\n",
        "        if obs_data is not None:\n",
        "          # 生成データを識別器に入力する場合\n",
        "            return [self.layers(i) for i in torch.unbind(obs_data.unsqueeze(1) * (1 - self.mask)\n",
        "                                                         + input.unsqueeze(1) * self.mask, 1)]\n",
        "            # 対角成分のみ生成したデータ、その他は観測データに\n",
        "            # データを各変数ごとに、生成したもの、その他観測したもので混ぜて、1変数ずつ生成したものを放り込む\n",
        "            # torch.unbind(x,1)はxの1次元目でテンソルをタプルに展開する\n",
        "            # minibatch数が2000、観測データの変数が6種類の場合、\n",
        "            # [2000,6]→[2000,6,6]→([2000,6], [2000,6], [2000,6], [2000,6], [2000,6], [2000,6])→([2000,1], [2000,1], [2000,1], [2000,1], [2000,1], [2000,1])\n",
        "            # returnは[torch.Size([2000, 1]),torch.Size([2000, 1]),torch.Size([2000, 1], torch.Size([2000, 1]),torch.Size([2000, 1]),torch.Size([2000, 1])]\n",
        "\n",
        "            # 注：生成した変数全種類を用いた判定はしない。\n",
        "            # すなわち、生成した変数1種類と、元の観測データたちをまとめて1つにし、それが観測結果か、生成結果を判定させる\n",
        "\n",
        "        else:\n",
        "            # 観測データを識別器に入力する場合\n",
        "\n",
        "            return self.layers(input)\n",
        "            # returnは[torch.Size([2000, 1])]\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"識別器Dの重みパラメータの初期化を実施\"\"\"\n",
        "        for layer in self.layers:\n",
        "            if hasattr(layer, 'reset_parameters'):\n",
        "                layer.reset_parameters()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yLyjZsSc1S2i"
      },
      "source": [
        "### SAMの生成器Gの実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pBUh-fKh8X-E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "76657466-5386-4f28-e431-0ffb1f8c837e"
      },
      "source": [
        "from cdt.utils.torch import ChannelBatchNorm1d, MatrixSampler, Linear3D\n",
        "\n",
        "\n",
        "class SAMGenerator(nn.Module):\n",
        "    \"\"\"SAMのGeneratorのニューラルネットワーク\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_shape, nh):\n",
        "        \"\"\"初期化\"\"\"\n",
        "        super(SAMGenerator, self).__init__()\n",
        "\n",
        "        # ----------------------------------\n",
        "        # 対角成分のみ0で、残りは1のmaskとなる変数skeletonを作成\n",
        "        # ※最後の行は、全部1です\n",
        "        # ----------------------------------\n",
        "        nb_vars = data_shape[1]  # 変数の数\n",
        "        skeleton = 1 - torch.eye(nb_vars + 1, nb_vars)\n",
        "\n",
        "        self.register_buffer('skeleton', skeleton)\n",
        "\n",
        "        # 注意：register_bufferはmodelのパラメータではないが、その後forwardで使う変数を登録するPyTorchのメソッドです\n",
        "        # self.変数名で、以降も使用可能になります\n",
        "        # https://pytorch.org/docs/stable/nn.html?highlight=register_buffer#torch.nn.Module.register_buffer\n",
        "\n",
        "        # ----------------------------------\n",
        "        # ネットワークの用意\n",
        "        # ----------------------------------\n",
        "        # 入力層（SAMの形での全結合層）　\n",
        "        self.input_layer = Linear3D(\n",
        "            (nb_vars, nb_vars + 1, nh))  # nhは中間層のニューロン数\n",
        "        # https://github.com/FenTechSolutions/CausalDiscoveryToolbox/blob/32200779ab9b63762be3a24a2147cff09ba2bb72/cdt/utils/torch.py#L289\n",
        "\n",
        "        # 中間層\n",
        "        layers = []\n",
        "        # 2次元を1次元に変換してバッチノーマライゼーションするモジュール\n",
        "        layers.append(ChannelBatchNorm1d(nb_vars, nh))\n",
        "        layers.append(nn.Tanh())\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "        # ChannelBatchNorm1d\n",
        "        # https://github.com/FenTechSolutions/CausalDiscoveryToolbox/blob/32200779ab9b63762be3a24a2147cff09ba2bb72/cdt/utils/torch.py#L130\n",
        "\n",
        "        # 出力層（再度、SAMの形での全結合層）\n",
        "        self.output_layer = Linear3D((nb_vars, nh, 1))\n",
        "\n",
        "    def forward(self, data, noise, adj_matrix, drawn_neurons=None):\n",
        "        \"\"\"　順伝搬の計算\n",
        "        Args:\n",
        "            data (torch.Tensor): 観測データ\n",
        "            noise (torch.Tensor): データ生成用のノイズ\n",
        "            adj_matrix (torch.Tensor): 因果関係を示す因果構造マトリクスM\n",
        "            drawn_neurons (torch.Tensor): Linear3Dの複雑さを制御する複雑さマトリクスZ\n",
        "        Returns:\n",
        "            torch.Tensor: 生成されたデータ\n",
        "        \"\"\"\n",
        "\n",
        "        # 入力層\n",
        "        x = self.input_layer(data, noise, adj_matrix *\n",
        "                             self.skeleton)  # Linear3D\n",
        "\n",
        "        # 中間層（バッチノーマライゼーションとTanh）\n",
        "        x = self.layers(x)\n",
        "\n",
        "        # 出力層\n",
        "        output = self.output_layer(\n",
        "            x, noise=None, adj_matrix=drawn_neurons)  # Linear3D\n",
        "\n",
        "        return output.squeeze(2)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"重みパラメータの初期化を実施\"\"\"\n",
        "\n",
        "        self.input_layer.reset_parameters()\n",
        "        self.output_layer.reset_parameters()\n",
        "\n",
        "        for layer in self.layers:\n",
        "            if hasattr(layer, 'reset_parameters'):\n",
        "                layer.reset_parameters()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detecting 1 CUDA device(s).\n",
            "sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2MubteRua0mj"
      },
      "source": [
        "### SAMの誤差関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hy2GqNNdapc6",
        "colab": {}
      },
      "source": [
        "# ネットワークを示す因果構造マトリクスMがDAG（有向非循環グラフ）になるように加える損失\n",
        "\n",
        "def notears_constr(adj_m, max_pow=None):\n",
        "    \"\"\"No Tears constraint for binary adjacency matrixes. \n",
        "    Args:\n",
        "        adj_m (array-like): Adjacency matrix of the graph\n",
        "        max_pow (int): maximum value to which the infinite sum is to be computed.\n",
        "           defaults to the shape of the adjacency_matrix\n",
        "    Returns:\n",
        "        np.ndarray or torch.Tensor: Scalar value of the loss with the type\n",
        "            depending on the input.\n",
        "    参考：https://github.com/FenTechSolutions/CausalDiscoveryToolbox/blob/32200779ab9b63762be3a24a2147cff09ba2bb72/cdt/utils/loss.py#L215\n",
        "    \"\"\"\n",
        "    m_exp = [adj_m]\n",
        "    if max_pow is None:\n",
        "        max_pow = adj_m.shape[1]\n",
        "    while(m_exp[-1].sum() > 0 and len(m_exp) < max_pow):\n",
        "        m_exp.append(m_exp[-1] @ adj_m/len(m_exp))\n",
        "\n",
        "    return sum([i.diag().sum() for idx, i in enumerate(m_exp)])\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d01nY6IKKmXe"
      },
      "source": [
        "### SAMの学習を実施する関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LdgNruwmJkxj",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import scale\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def run_SAM(in_data, lr_gen, lr_disc, lambda1, lambda2, hlayers, nh, dnh, train_epochs, test_epochs, device):\n",
        "    '''SAMの学習を実行する関数'''\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # 入力データの前処理\n",
        "    # ---------------------------------------------------\n",
        "    list_nodes = list(in_data.columns)  # 入力データの列名のリスト\n",
        "    data = scale(in_data[list_nodes].values)  # 入力データの正規化\n",
        "    nb_var = len(list_nodes)  # 入力データの数 = d\n",
        "    data = data.astype('float32')  # 入力データをfloat32型に\n",
        "    data = torch.from_numpy(data).to(device)  # 入力データをPyTorchのテンソルに\n",
        "    rows, cols = data.size()  # rowsはデータ数、colsは変数の数\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # DataLoaderの作成（バッチサイズは全データ）\n",
        "    # ---------------------------------------------------\n",
        "    batch_size = rows  # 入力データ全てを使用したミニバッチ学習とする\n",
        "    data_iterator = DataLoader(data, batch_size=batch_size,\n",
        "                               shuffle=True, drop_last=True)\n",
        "    # 注意：引数のdrop_lastはdataをbatch_sizeで取り出していったときに最後に余ったものは使用しない設定\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # 【Generator】ネットワークの生成とパラメータの初期化\n",
        "    # cols：入力変数の数、nhは中間ニューロンの数、hlayersは中間層の数\n",
        "    # neuron_samplerは、Functional gatesの変数zを学習するネットワーク\n",
        "    # graph_samplerは、Structual gatesの変数aを学習するネットワーク\n",
        "    # ---------------------------------------------------\n",
        "    sam = SAMGenerator((batch_size, cols), nh).to(device)  # 生成器G\n",
        "    graph_sampler = MatrixSampler(nb_var, mask=None, gumbel=False).to(\n",
        "        device)  # 因果構造マトリクスMを作るネットワーク\n",
        "    neuron_sampler = MatrixSampler((nh, nb_var), mask=False, gumbel=True).to(\n",
        "        device)  # 複雑さマトリクスZを作るネットワーク\n",
        "\n",
        "    # 注意：MatrixSamplerはGumbel-Softmaxを使用し、0か1を出力させるニューラルネットワーク\n",
        "    # SAMの著者らの実装モジュール、MatrixSamplerを使用\n",
        "    # https://github.com/FenTechSolutions/CausalDiscoveryToolbox/blob/32200779ab9b63762be3a24a2147cff09ba2bb72/cdt/utils/torch.py#L212\n",
        "\n",
        "    # 重みパラメータの初期化\n",
        "    sam.reset_parameters()\n",
        "    graph_sampler.weights.data.fill_(2)\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # 【Discriminator】ネットワークの生成とパラメータの初期化\n",
        "    # cols：入力変数の数、dnhは中間ニューロンの数、hlayersは中間層の数。\n",
        "    # ---------------------------------------------------\n",
        "    discriminator = SAMDiscriminator(cols, dnh, hlayers).to(device)\n",
        "    discriminator.reset_parameters()  # 重みパラメータの初期化\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # 最適化の設定\n",
        "    # ---------------------------------------------------\n",
        "    # 生成器\n",
        "\n",
        "    g_optimizer = optim.Adam(sam.parameters(), lr=lr_gen)\n",
        "    graph_optimizer = optim.Adam(graph_sampler.parameters(), lr=lr_gen)\n",
        "    neuron_optimizer = optim.Adam(neuron_sampler.parameters(), lr=lr_gen)\n",
        "\n",
        "    # 識別器\n",
        "    d_optimizer = optim.Adam(discriminator.parameters(), lr=lr_disc)\n",
        "\n",
        "    # 損失関数\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    # nn.BCEWithLogitsLoss()は、binary cross entropy with Logistic function\n",
        "    # https://pytorch.org/docs/stable/nn.html#bcewithlogitsloss\n",
        "\n",
        "    # 損失関数のDAGに関する制約の設定パラメータ\n",
        "    dagstart = 0.5\n",
        "    dagpenalization_increase = 0.001*10\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # forward計算、および損失関数の計算に使用する変数を用意\n",
        "    # ---------------------------------------------------\n",
        "    _true = torch.ones(1).to(device)\n",
        "    _false = torch.zeros(1).to(device)\n",
        "\n",
        "    noise = torch.randn(batch_size, nb_var).to(device)  # 生成器Gで使用する生成ノイズ\n",
        "    noise_row = torch.ones(1, nb_var).to(device)\n",
        "\n",
        "    output = torch.zeros(nb_var, nb_var).to(device)  # 求まった隣接行列\n",
        "    output_loss = torch.zeros(1, 1).to(device)\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # forwardの計算で、ネットワークを学習させる\n",
        "    # ---------------------------------------------------\n",
        "    pbar = tqdm(range(train_epochs + test_epochs),mininterval=1)  # 進捗（progressive bar）の表示\n",
        "\n",
        "    for epoch in pbar:\n",
        "        for i_batch, batch in enumerate(data_iterator):\n",
        "\n",
        "            # 最適化を初期化\n",
        "            g_optimizer.zero_grad()\n",
        "            graph_optimizer.zero_grad()\n",
        "            neuron_optimizer.zero_grad()\n",
        "            d_optimizer.zero_grad()\n",
        "\n",
        "            # 因果構造マトリクスM（drawn_graph）と複雑さマトリクスZ（drawn_neurons）をMatrixSamplerから取得\n",
        "            drawn_graph = graph_sampler()\n",
        "            drawn_neurons = neuron_sampler()\n",
        "            # (drawn_graph)のサイズは、torch.Size([nb_var, nb_var])。 出力値は0か1\n",
        "            # (drawn_neurons)のサイズは、torch.Size([nh, nb_var])。 出力値は0か1\n",
        "\n",
        "            # ノイズをリセットし、生成器Gで疑似データを生成\n",
        "            noise.normal_()\n",
        "            generated_variables = sam(data=batch, noise=noise,\n",
        "                                      adj_matrix=torch.cat(\n",
        "                                          [drawn_graph, noise_row], 0),\n",
        "                                      drawn_neurons=drawn_neurons)\n",
        "\n",
        "            # 識別器Dで判定\n",
        "            # 観測変数のリスト[]で、各torch.Size([data数, 1])が求まる\n",
        "            disc_vars_d = discriminator(generated_variables.detach(), batch)\n",
        "            # 観測変数のリスト[] で、各torch.Size([data数, 1])が求まる\n",
        "            disc_vars_g = discriminator(generated_variables, batch)\n",
        "            true_vars_disc = discriminator(batch)  # torch.Size([data数, 1])が求まる\n",
        "\n",
        "            # 損失関数の計算（DCGAN）\n",
        "            disc_loss = sum([criterion(gen, _false.expand_as(gen)) for gen in disc_vars_d]) / nb_var \\\n",
        "                + criterion(true_vars_disc, _true.expand_as(true_vars_disc))\n",
        "\n",
        "            gen_loss = sum([criterion(gen,\n",
        "                                      _true.expand_as(gen))\n",
        "                            for gen in disc_vars_g])\n",
        "\n",
        "            # 損失の計算（SAM論文のオリジナルのfgan）\n",
        "            #disc_loss = sum([torch.mean(torch.exp(gen - 1)) for gen in disc_vars_d]) / nb_var - torch.mean(true_vars_disc)\n",
        "            #gen_loss = -sum([torch.mean(torch.exp(gen - 1)) for gen in disc_vars_g])\n",
        "\n",
        "            # 識別器Dのバックプロパゲーションとパラメータの更新\n",
        "            if epoch < train_epochs:\n",
        "                disc_loss.backward()\n",
        "                d_optimizer.step()\n",
        "\n",
        "            # 生成器のGの損失の計算の残り（マトリクスの複雑さとDAGのNO TEAR）\n",
        "            struc_loss = lambda1 / batch_size*drawn_graph.sum()     # Mのloss\n",
        "            func_loss = lambda2 / batch_size*drawn_neurons.sum()   # Aのloss\n",
        "\n",
        "            regul_loss = struc_loss + func_loss\n",
        "\n",
        "            if epoch <= train_epochs * dagstart:\n",
        "                # epochが基準前のときは、DAGになるようにMへのNO TEARSの制限はかけない\n",
        "                loss = gen_loss + regul_loss\n",
        "\n",
        "            else:\n",
        "                # epochが基準後のときは、DAGになるようにNO TEARSの制限をかける\n",
        "                filters = graph_sampler.get_proba()  # マトリクスMの要素を取得（ただし、0,1ではなく、1の確率）\n",
        "                dag_constraint = notears_constr(filters*filters)  # NO TERARの計算\n",
        "\n",
        "                # 徐々に線形にDAGの正則を強くする\n",
        "                loss = gen_loss + regul_loss + \\\n",
        "                    ((epoch - train_epochs * dagstart) *\n",
        "                     dagpenalization_increase) * dag_constraint\n",
        "\n",
        "            if epoch >= train_epochs:\n",
        "                # testのepochの場合、結果を取得\n",
        "                output.add_(filters.data)\n",
        "                output_loss.add_(gen_loss.data)\n",
        "            else:\n",
        "                # trainのepochの場合、生成器Gのバックプロパゲーションと更新\n",
        "                # retain_graph=Trueにすることで、以降3つのstep()が実行できる\n",
        "                loss.backward(retain_graph=True)\n",
        "                g_optimizer.step()\n",
        "                graph_optimizer.step()\n",
        "                neuron_optimizer.step()\n",
        "\n",
        "            # 進捗の表示\n",
        "            if epoch % 50 == 0:\n",
        "                pbar.set_postfix(gen=gen_loss.item()/cols,\n",
        "                                 disc=disc_loss.item(),\n",
        "                                 regul_loss=regul_loss.item(),\n",
        "                                 tot=loss.item())\n",
        "\n",
        "    return output.cpu().numpy()/test_epochs, output_loss.cpu().numpy()/test_epochs/cols  # Mと損失を出力\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S5SXuXOCUgmg"
      },
      "source": [
        "### GPUの使用可能を確認\n",
        "\n",
        "画面上部のメニュー ランタイム > ランタイムのタイプを変更 で、 ノートブックの設定 を開く\n",
        "\n",
        "ハードウェアアクセラレータに GPU を選択し、 保存 する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ClTdYzxzXsL2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21354e17-11ae-4e33-92c2-6472518af696"
      },
      "source": [
        "# GPUの使用確認：True or False\n",
        "torch.cuda.is_available()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R-FzZ-W3Xseu"
      },
      "source": [
        "### SAMの学習を実施"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xfqAztolY1fo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1d7ad4d4-6c86-4c0d-f65f-e34222ed506d"
      },
      "source": [
        "# numpyの出力を小数点2桁に\n",
        "np.set_printoptions(precision=2, floatmode='fixed', suppress=True)\n",
        "\n",
        "# 因果探索の結果を格納するリスト\n",
        "m_list = []\n",
        "loss_list = []\n",
        "\n",
        "for i in range(5):\n",
        "    m, loss = run_SAM(in_data=df, lr_gen=0.01*0.5,\n",
        "                      lr_disc=0.01*0.5*2,\n",
        "                      #lambda1=0.01, lambda2=1e-05,\n",
        "                      lambda1=5.0*20, lambda2=0.005*20,\n",
        "                      hlayers=2,\n",
        "                      nh=200, dnh=200,\n",
        "                      train_epochs=10000,\n",
        "                      test_epochs=1000,\n",
        "                      device='cuda:0')\n",
        "\n",
        "    print(loss)\n",
        "    print(m)\n",
        "\n",
        "    m_list.append(m)\n",
        "    loss_list.append(loss)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 11000/11000 [05:27<00:00, 33.62it/s, disc=0.477, gen=8.56, regul_loss=2.74, tot=115]\n",
            "  0%|          | 0/11000 [00:00<?, ?it/s, disc=1.41, gen=0.678, regul_loss=12, tot=19.5]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[7.81]]\n",
            "[[0.00 0.01 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.82 0.00]\n",
            " [0.96 0.00 0.96 0.85 0.02 1.00 0.00 0.00 0.02 0.00 0.00]\n",
            " [0.99 0.04 0.00 0.00 0.00 0.82 0.00 0.00 0.00 0.00 0.00]\n",
            " [0.95 0.00 0.83 0.00 0.02 0.99 0.00 0.00 0.00 0.03 0.01]\n",
            " [0.88 0.92 0.00 0.99 0.00 0.99 0.00 0.00 0.11 1.00 0.01]\n",
            " [0.99 0.01 0.02 0.00 0.00 0.00 0.00 0.00 0.99 0.73 0.02]\n",
            " [0.00 0.00 0.92 0.00 0.00 0.00 0.00 0.99 0.00 0.86 0.00]\n",
            " [0.99 0.00 0.00 0.00 0.99 0.94 0.38 0.00 0.00 0.00 0.00]\n",
            " [0.00 0.00 0.01 0.01 0.00 0.01 0.00 0.00 0.00 0.99 1.00]\n",
            " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01]\n",
            " [0.01 0.00 0.00 0.04 0.01 0.01 0.00 0.00 0.01 0.99 0.00]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 11000/11000 [05:19<00:00, 34.38it/s, disc=0.676, gen=7.83, regul_loss=2.96, tot=166]\n",
            "  0%|          | 0/11000 [00:00<?, ?it/s, disc=1.42, gen=0.765, regul_loss=12.1, tot=20.5]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[7.99]]\n",
            "[[0.00 0.98 0.05 0.17 0.96 0.98 0.00 0.00 0.01 0.00 0.00]\n",
            " [0.03 0.00 0.05 0.01 0.98 1.00 0.00 0.00 0.00 0.02 0.00]\n",
            " [0.01 0.99 0.00 0.29 1.00 0.95 0.00 0.00 0.00 0.00 0.00]\n",
            " [0.09 0.99 0.09 0.00 0.24 1.00 0.00 0.09 0.00 0.00 0.00]\n",
            " [0.00 0.02 0.01 0.03 0.00 0.96 0.00 0.01 0.00 0.00 0.00]\n",
            " [0.01 0.01 0.01 0.02 0.02 0.00 0.00 0.00 0.00 0.00 0.00]\n",
            " [0.00 0.93 0.81 0.03 0.00 0.83 0.00 0.79 0.00 0.11 0.00]\n",
            " [0.96 0.00 0.00 0.00 0.88 0.01 0.96 0.00 0.00 0.00 0.00]\n",
            " [0.90 0.00 0.71 0.82 0.00 0.84 0.00 0.00 0.00 0.04 1.00]\n",
            " [0.00 0.00 0.04 0.00 0.00 0.00 0.00 0.00 0.59 0.00 0.18]\n",
            " [0.24 0.00 0.71 0.00 0.31 0.03 0.00 0.00 0.11 0.09 0.00]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 11000/11000 [05:15<00:00, 34.89it/s, disc=0.325, gen=8.85, regul_loss=3.63, tot=120]\n",
            "  0%|          | 0/11000 [00:00<?, ?it/s, disc=1.41, gen=0.725, regul_loss=12.4, tot=20.3]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[8.64]]\n",
            "[[0.00 0.00 0.01 0.00 1.00 0.84 0.00 0.00 0.00 0.01 0.00]\n",
            " [0.89 0.00 0.98 0.39 1.00 0.97 0.00 0.00 0.97 0.01 0.00]\n",
            " [0.92 0.01 0.00 0.03 1.00 0.98 0.00 0.00 0.00 0.00 0.00]\n",
            " [0.96 0.02 0.83 0.00 0.99 0.99 0.00 0.00 0.00 0.00 0.00]\n",
            " [0.00 0.00 0.00 0.00 0.00 0.98 0.00 0.00 0.00 0.00 0.00]\n",
            " [0.01 0.01 0.00 0.01 0.01 0.00 0.00 0.00 0.00 0.00 0.00]\n",
            " [0.00 0.89 0.98 0.68 0.00 0.80 0.00 1.00 0.00 0.00 0.00]\n",
            " [0.99 0.91 0.00 0.00 0.97 0.00 0.39 0.00 0.00 0.00 0.00]\n",
            " [0.83 0.00 0.95 0.00 0.79 0.00 0.00 0.00 0.00 0.77 0.99]\n",
            " [0.00 0.02 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.67]\n",
            " [0.00 0.00 0.93 0.93 0.21 0.94 0.02 0.00 0.07 0.03 0.00]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 11000/11000 [05:14<00:00, 34.96it/s, disc=0.358, gen=8.79, regul_loss=3.63, tot=118]\n",
            "  0%|          | 0/11000 [00:00<?, ?it/s, disc=1.42, gen=0.65, regul_loss=12.1, tot=19.3]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[8.01]]\n",
            "[[0.00 0.99 0.08 0.12 1.00 0.97 0.00 0.07 0.00 0.99 0.00]\n",
            " [0.00 0.00 0.04 0.01 0.34 0.98 0.00 0.00 0.00 0.00 0.00]\n",
            " [0.14 0.99 0.00 0.01 1.00 0.99 0.00 0.00 0.00 0.84 0.00]\n",
            " [0.02 0.90 0.73 0.00 0.01 1.00 0.00 0.00 0.00 0.00 0.00]\n",
            " [0.00 0.08 0.00 0.00 0.00 0.99 0.00 0.01 0.00 0.00 0.00]\n",
            " [0.00 0.06 0.00 0.01 0.02 0.00 0.00 0.00 0.00 0.01 0.00]\n",
            " [0.98 0.00 0.00 0.00 0.92 0.00 0.00 0.90 0.00 0.00 0.08]\n",
            " [0.00 0.94 0.95 0.98 0.01 0.81 0.40 0.00 0.00 0.00 0.00]\n",
            " [0.90 0.83 0.38 0.94 0.95 0.72 0.00 0.00 0.00 1.00 0.05]\n",
            " [0.00 0.81 0.02 0.00 0.10 0.00 0.00 0.00 0.00 0.00 0.02]\n",
            " [0.00 0.00 0.92 0.90 0.70 0.91 0.00 0.12 1.00 0.91 0.00]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 11000/11000 [05:16<00:00, 34.81it/s, disc=0.571, gen=7.12, regul_loss=2.96, tot=99.5]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[7.93]]\n",
            "[[0.00 0.01 0.00 0.00 0.02 0.02 0.00 0.00 0.00 0.01 0.00]\n",
            " [0.94 0.00 0.01 0.01 0.02 0.04 0.00 0.00 0.00 0.01 0.00]\n",
            " [0.95 0.60 0.00 0.01 0.99 0.97 0.00 0.00 0.00 0.00 0.00]\n",
            " [0.95 0.97 0.98 0.00 0.03 1.00 0.00 0.00 0.00 0.00 0.00]\n",
            " [0.08 0.98 0.00 0.01 0.00 0.02 0.00 0.00 0.00 0.00 0.00]\n",
            " [0.00 0.97 0.05 0.00 0.97 0.00 0.00 0.00 0.00 0.91 0.00]\n",
            " [0.99 0.00 0.86 0.71 0.51 0.97 0.00 1.00 0.00 0.00 0.00]\n",
            " [0.00 0.00 0.00 0.00 0.00 0.00 0.38 0.00 0.00 0.00 0.00]\n",
            " [0.03 0.00 0.83 0.00 0.00 0.96 0.00 0.00 0.00 0.99 0.00]\n",
            " [0.00 0.57 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
            " [0.29 0.00 0.95 0.96 0.98 0.73 0.00 0.00 1.00 0.01 0.00]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7nTfo2_BjZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0eb92c71-987a-4bf8-9a71-2b665a094082"
      },
      "source": [
        "# ネットワーク構造（5回の平均）\n",
        "final_m = sum(m_list) / len(m_list)\n",
        "print(final_m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00 0.40 0.03 0.06 0.59 0.56 0.00 0.01 0.00 0.37 0.00]\n",
            " [0.56 0.00 0.41 0.25 0.47 0.80 0.00 0.00 0.20 0.01 0.00]\n",
            " [0.60 0.53 0.00 0.07 0.80 0.94 0.00 0.00 0.00 0.17 0.00]\n",
            " [0.59 0.58 0.69 0.00 0.26 0.99 0.00 0.02 0.00 0.01 0.00]\n",
            " [0.19 0.40 0.00 0.21 0.00 0.79 0.00 0.00 0.02 0.20 0.00]\n",
            " [0.20 0.21 0.02 0.01 0.20 0.00 0.00 0.00 0.20 0.33 0.01]\n",
            " [0.40 0.36 0.71 0.28 0.29 0.52 0.00 0.94 0.00 0.20 0.02]\n",
            " [0.59 0.37 0.19 0.20 0.57 0.35 0.50 0.00 0.00 0.00 0.00]\n",
            " [0.53 0.17 0.58 0.35 0.35 0.51 0.00 0.00 0.00 0.76 0.61]\n",
            " [0.00 0.28 0.01 0.00 0.02 0.00 0.00 0.00 0.12 0.00 0.18]\n",
            " [0.11 0.00 0.70 0.57 0.44 0.53 0.00 0.02 0.44 0.41 0.00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEJ1_U9D8uyw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "11f67f37-cf8c-415c-da93-74c639c4d75b"
      },
      "source": [
        "#閾値設定して1,0にする\n",
        "threshold = 0.6\n",
        "np.array([[1 if j > threshold else 0 for j in i] for i in final_m])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d010cf1713fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#閾値設定して1,0にする\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfinal_m\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm8XfqNswcAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bb2ff7f8-bb24-4134-d1d7-69295debb80a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Sex_female</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Pclass   Age  SibSp  ...  Sex_male  Embarked_C  Embarked_Q  Embarked_S\n",
              "0         0       3  22.0      1  ...         1           0           0           1\n",
              "1         1       1  38.0      1  ...         0           1           0           0\n",
              "2         1       3  26.0      0  ...         0           0           0           1\n",
              "3         1       1  35.0      1  ...         0           0           0           1\n",
              "4         0       3  35.0      0  ...         1           0           0           1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MGNG7pzi8LI6"
      },
      "source": [
        "以上"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQZTue8K1IGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}